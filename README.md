# NYC Taxi Streaming Pipeline ğŸš•ğŸ“Š

A real-time data engineering project that streams **NYC Taxi Trip data** from a producer into **Kafka**, processes it with **PyFlink**, and stores the transformed results into **PostgreSQL** for downstream analytics.  

---

## ğŸ“Œ Project Overview
This project simulates a **real-time streaming pipeline**:
1. **Producer (Python)**  
   Reads NYC Taxi trip data (Parquet/CSV) and sends events into **Kafka**.
2. **Kafka**  
   Acts as the **message broker** to handle real-time event streams.
3. **PyFlink**  
   Consumes events from Kafka, applies simple **transformations**, and prepares data for storage.
4. **PostgreSQL**  
   Stores processed trip records for analytics, BI dashboards, and reporting.

---

## âš™ï¸ Tech Stack
- **Apache Kafka** â€“ Event streaming platform  
- **Apache Flink (PyFlink)** â€“ Real-time stream processing  
- **PostgreSQL** â€“ Analytical database  
- **Docker Compose** â€“ Container orchestration  
- **Python** â€“ Data producer & ETL logic  

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/your-username/nyc-taxi-streaming-pipeline.git
cd nyc-taxi-streaming-pipeline
  end

2ï¸âƒ£ Start Services with Docker
docker-compose up -d


This starts:

Kafka broker

Flink (JobManager + TaskManager)

PostgreSQL

PGAdmin

3ï¸âƒ£ Run Producer (send taxi trip events to Kafka)
cd src/producers
python producer.py

4ï¸âƒ£ Submit Flink Job (consume + transform + write to Postgres)
docker cp src/job/taxi_job.py flink-jobmanager:/opt/flink/usrlib/
docker exec -it flink-jobmanager ./bin/flink run -py /opt/flink/usrlib/taxi_job.py

ğŸ“‚ Project Structure
nyc-taxi-streaming-pipeline/
â”‚â”€â”€ docker-compose.yml      # Service definitions
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ producers/
â”‚   â”‚   â””â”€â”€ producer.py     # Sends NYC taxi events to Kafka
â”‚   â””â”€â”€ job/
â”‚       â””â”€â”€ taxi_job.py     # PyFlink job (Kafka -> Postgres)
â”‚â”€â”€ scripts/
â”‚   â””â”€â”€ create_tables.sql   # PostgreSQL schema
â”‚â”€â”€ README.md               # Documentation

ğŸ“Š Example Table Schema
CREATE TABLE taxi_events(
    lpep_pickup_datetime TIMESTAMP,
    lpep_dropoff_datetime TIMESTAMP,
    PULocationID INT,
    DOLocationID INT,
    passenger_count INT,
    trip_distance DOUBLE PRECISION,
    tip_amount DOUBLE PRECISION
);

âœ… Features

Real-time data ingestion

Stream transformations with PyFlink

Storage into PostgreSQL

Easily extensible for BI tools

ğŸ“Œ Future Improvements

Add dbt transformations in Postgres

Integrate Apache Superset / Power BI for visualization

Deploy to cloud (AWS/GCP/Azure)

ğŸ‘¨â€ğŸ’» Author

Hussnain
Data Engineering Intern | Building scalable data pipelines







